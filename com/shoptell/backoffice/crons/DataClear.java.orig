/***************************************************************************
 * Copyright (c) 2016 AFFERVE.COM - All rights reserved.
 * Unauthorized copying of this file, via any medium is strictly prohibited.
 * Proprietary and confidential.
 * 
 * Contributors:
 *     Abhishek Agarwal 	- abhishek@afferve.com
 *     Ravi Kumar 			- ravi@afferve.com
 ****************************************************************************/
package com.shoptell.backoffice.crons;

import java.util.Date;
import java.util.HashMap;
import java.util.Iterator;
import java.util.Map;

import javax.annotation.PostConstruct;
import javax.inject.Inject;
import javax.inject.Named;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.core.env.Environment;
import org.springframework.scheduling.annotation.Async;
import org.springframework.scheduling.annotation.Scheduled;

import com.datastax.driver.core.BatchStatement;
import com.datastax.driver.core.ResultSet;
import com.datastax.driver.core.Row;
import com.datastax.driver.core.Session;
import com.datastax.driver.core.querybuilder.QueryBuilder;
import com.datastax.driver.core.querybuilder.Select;
import com.shoptell.backoffice.BackofficeConstants;
import com.shoptell.backoffice.BackofficeProcessor;
import com.shoptell.backoffice.enums.TableEnum;
import com.shoptell.backoffice.repository.CountQuery;
import com.shoptell.db.processlog.ProcessLog;
import com.shoptell.db.processlog.ProcessLogUtil;
import com.shoptell.util.stproperties.STProperties;

@Named(value = "DataClear")
public class DataClear {

	private static final Logger log = LoggerFactory.getLogger(BackofficeProcessor.class);

	@Inject
	private Session session;
	@Inject
	private Environment env;
	@Inject
	protected STProperties stprop;
	@Inject
	private CountQuery countQuery;

	private String keyspace;
	@Inject
	private ProcessLogUtil process_log;

	@PostConstruct
	public void start() {
		keyspace = env.getProperty(BackofficeConstants.KEYSPACENAME_VAR);
	}

	/*@Scheduled(cron = "${cron.job.dataclear}")*/
	@Async
	public void init() {
		log.info("init() Enter");
		ProcessLog pLog = process_log.start("ALL", "DATA CLEAR");
		productTableClear();
		reviewTableClear();
		mergePropertiesTableClear();
		mergeInfoTableClear();
		partnerCouponsClear();
		process_log.end(pLog);
		log.info("init() Exit");
	}

	private void partnerCouponsClear() {
		log.info("partnerCouponsClear() Enter");
		BatchStatement batch = new BatchStatement();
		Select stmt = QueryBuilder.select("home", "time", "expiredate").from(keyspace, TableEnum.partner_coupons.name());
		stmt.setFetchSize(BackofficeConstants.FETCHSIZE);
		ResultSet rows = session.execute(stmt);
		Date clearDate = new Date(System.currentTimeMillis());
		if (rows != null) {
			Iterator<Row> rs = rows.iterator();
			while (rs.hasNext()) {
				Row tmp = rs.next();
				Date expireOn = tmp.getDate("expiredate");
				if (expireOn != null && clearDate.before(expireOn)) {
					continue;
				}
				batch.add(QueryBuilder.delete().all().from(keyspace, TableEnum.partner_coupons.name()).where(QueryBuilder.eq("home", tmp.getString("home")))
						.and(QueryBuilder.eq("time", tmp.getUUID("time"))));

				if (batch.size() > BackofficeConstants.BATCHSIZE) {
					session.execute(batch);
					batch.clear();
				}
			}
		}
		session.execute(batch);
		batch.clear();
		log.info("partnerCouponsClear() Exit");
	}

	private void reviewTableClear() {
		log.info("reviewTableClear() Enter");
		BatchStatement batch = new BatchStatement();
		Select stmt = QueryBuilder.select("home", "subcategoryname", "id").from(keyspace, TableEnum.reviewed_product_info.name());
		stmt.setFetchSize(BackofficeConstants.FETCHSIZE);
		ResultSet rows = session.execute(stmt);
		if (rows != null) {
			Iterator<Row> rs = rows.iterator();
			while (rs.hasNext()) {
				Row tmp = rs.next();
				
				Map<String, Object> map = new HashMap<String, Object>();
				map.put("home", tmp.getString("home"));
				map.put("subcategoryname", tmp.getString("subcategoryname"));
				map.put("id", tmp.getString("id"));
				
				long count = countQuery.countAll(TableEnum.home_product_info, map);
				
				if (count == 0) {
					batch.add(QueryBuilder.delete().all().from(keyspace, TableEnum.reviewed_product_info.name())
							.where(QueryBuilder.eq("home", tmp.getString("home"))).and(QueryBuilder.eq("subcategoryname", tmp.getString("subcategoryname")))
							.and(QueryBuilder.eq("id", tmp.getString("id"))));
				}

				if (batch.size() > BackofficeConstants.BATCHSIZE) {
					session.execute(batch);
					batch.clear();
				}
			}
		}
		session.execute(batch);
		batch.clear();
		log.info("reviewTableClear() Exit");
	}

	private void mergeInfoTableClear() {
		log.info("mergeInfoTableClear() Enter");
		BatchStatement batch = new BatchStatement();
		Select stmt = QueryBuilder.select("id").from(keyspace, TableEnum.merged_product_info.name());
		stmt.setFetchSize(BackofficeConstants.FETCHSIZE);
		ResultSet rows = session.execute(stmt);
		if (rows != null) {
			Iterator<Row> rs = rows.iterator();
			while (rs.hasNext()) {
				Row tmp = rs.next();
				
				Map<String, Object> map = new HashMap<String, Object>();
				map.put("mergeprodid", tmp.getUUID("id"));
				long count = countQuery.countAll(TableEnum.merged_product_properties, map);
				
				if (count == 0) {
					batch.add(QueryBuilder.delete().all().from(keyspace, TableEnum.merged_product_info.name()).where(QueryBuilder.eq("id", tmp.getUUID("id"))));

					if (batch.size() > BackofficeConstants.BATCHSIZE) {
						session.execute(batch);
						batch.clear();
					}
				}
			}
		}
		session.execute(batch);
		batch.clear();
		log.info("mergeInfoTableClear() Exit");
	}

	private void mergePropertiesTableClear() {
		log.info("mergePropertiesTableClear() Enter");
		BatchStatement batch = new BatchStatement();
		Select stmt = QueryBuilder.select("mergeprodid", "id").from(keyspace, TableEnum.merged_product_properties.name());
		stmt.setFetchSize(BackofficeConstants.FETCHSIZE);
		ResultSet rows = session.execute(stmt);
		if (rows != null) {
			Iterator<Row> rs = rows.iterator();
			while (rs.hasNext()) {
				Row tmp = rs.next();
				Map<String, Object> map = new HashMap<String, Object>();
				map.put("mergeprodinfoid", tmp.getUUID("id"));
				long count = countQuery.countAll(TableEnum.reviewed_product_info, map);
				if (count == 0) {
					batch.add(QueryBuilder.delete().all().from(keyspace, TableEnum.merged_product_properties.name())
							.where(QueryBuilder.eq("mergeprodid", tmp.getUUID("mergeprodid"))).and(QueryBuilder.eq("id", tmp.getUUID("id"))));

					if (batch.size() > BackofficeConstants.BATCHSIZE) {
						session.execute(batch);
						batch.clear();
					}
				}
			}
		}
		session.execute(batch);
		batch.clear();
		log.info("mergePropertiesTableClear() Exit");
	}

	private void productTableClear() {
		log.info("productTableClear() Enter");
		BatchStatement batch = new BatchStatement();
		Select stmt = QueryBuilder.select("home", "subcategoryname", "id", "createdon", "modifiedon").from(keyspace, TableEnum.home_product_info.name());
		stmt.setFetchSize(BackofficeConstants.FETCHSIZE);
		ResultSet rows = session.execute(stmt);
		Date clearDate = new Date(System.currentTimeMillis() - BackofficeConstants.ONE_DAY * 30);
		if (rows != null) {
			Iterator<Row> rs = rows.iterator();
			while (rs.hasNext()) {
				Row tmp = rs.next();
				Date createdOn = tmp.getDate("createdon");
				if (createdOn != null) {
					if (clearDate.before(createdOn)) {
						continue;
					}
					Date modifiedOn = tmp.getDate("modifiedon");
					if (modifiedOn != null && clearDate.before(modifiedOn)) {
						continue;
					}
					batch.add(QueryBuilder.delete().all().from(keyspace, TableEnum.home_product_info.name())
							.where(QueryBuilder.eq("home", tmp.getString("home"))).and(QueryBuilder.eq("subcategoryname", tmp.getString("subcategoryname")))
							.and(QueryBuilder.eq("id", tmp.getString("id"))));

					if (batch.size() > BackofficeConstants.BATCHSIZE) {
						session.execute(batch);
						batch.clear();
					}
				}
			}
		}
		session.execute(batch);
		batch.clear();
		log.info("productTableClear() Exit");
	}
}
